{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f07cc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-3.1.3-py3-none-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Downloading xgboost-3.1.3-py3-none-win_amd64.whl (72.0 MB)\n",
      "   ---------------------------------------- 0.0/72.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.8/72.0 MB 8.5 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 5.0/72.0 MB 16.8 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 10.0/72.0 MB 20.7 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 12.1/72.0 MB 21.6 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 13.1/72.0 MB 15.8 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 14.2/72.0 MB 13.3 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 14.9/72.0 MB 11.9 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 19.1/72.0 MB 12.8 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 21.2/72.0 MB 12.7 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 23.9/72.0 MB 12.6 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 27.0/72.0 MB 12.6 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 30.7/72.0 MB 13.3 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 32.8/72.0 MB 12.7 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 34.9/72.0 MB 12.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 37.5/72.0 MB 12.6 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 38.8/72.0 MB 12.1 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 40.9/72.0 MB 12.0 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 43.0/72.0 MB 12.0 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 44.8/72.0 MB 11.8 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 47.2/72.0 MB 11.8 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 48.2/72.0 MB 11.4 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 49.5/72.0 MB 11.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 51.9/72.0 MB 11.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 53.5/72.0 MB 11.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 55.1/72.0 MB 10.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 56.1/72.0 MB 10.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 56.9/72.0 MB 10.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 58.2/72.0 MB 10.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 59.0/72.0 MB 9.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 60.0/72.0 MB 9.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 61.1/72.0 MB 9.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 62.7/72.0 MB 9.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 63.7/72.0 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 65.3/72.0 MB 9.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 65.8/72.0 MB 9.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 66.8/72.0 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 67.6/72.0 MB 8.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 68.4/72.0 MB 8.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 68.9/72.0 MB 8.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 70.0/72.0 MB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  71.3/72.0 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  71.8/72.0 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 72.0/72.0 MB 8.3 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2f08555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart columns:\n",
      "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalch',\n",
      "       'exang', 'oldpeak', 'num'],\n",
      "      dtype='object')\n",
      "\n",
      "Diabetes columns:\n",
      "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
      "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
      "      dtype='object')\n",
      "\n",
      "Breast Cancer columns:\n",
      "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
      "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
      "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
      "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
      "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
      "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
      "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
      "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
      "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Heart columns:\")\n",
    "print(pd.read_csv(\"datasets/heart.csv\").columns)\n",
    "\n",
    "print(\"\\nDiabetes columns:\")\n",
    "print(pd.read_csv(\"datasets/diabetes.csv\").columns)\n",
    "\n",
    "print(\"\\nBreast Cancer columns:\")\n",
    "print(pd.read_csv(\"datasets/breast_cancer.csv\").columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1261ae0d",
   "metadata": {},
   "source": [
    "# SECTION 1: IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5c9b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b5d66d",
   "metadata": {},
   "source": [
    "# SECTION 2: TRAIN FUNCTION (HIGH ACCURACY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bf66653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_model(csv_path, target_col, model_name, drop_cols=None):\n",
    "\n",
    "    data = pd.read_csv(csv_path)\n",
    "\n",
    "    if drop_cols:\n",
    "        data = data.drop(columns=drop_cols, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4549ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_model(csv_path, target_col, model_name, drop_cols=None):\n",
    "\n",
    "    data = pd.read_csv(csv_path)\n",
    "\n",
    "    if drop_cols:\n",
    "        data = data.drop(columns=drop_cols, errors=\"ignore\")\n",
    "\n",
    "    # Encode categorical columns\n",
    "    encoders = {}\n",
    "    for col in data.columns:\n",
    "        if data[col].dtype == \"object\":\n",
    "            le = LabelEncoder()\n",
    "            data[col] = le.fit_transform(data[col])\n",
    "            encoders[col] = le\n",
    "\n",
    "    # Binary conversion for Heart Disease\n",
    "    if model_name == \"heart\":\n",
    "        data[target_col] = (data[target_col] > 0).astype(int)\n",
    "\n",
    "    X = data.drop(target_col, axis=1)\n",
    "    y = data[target_col]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        stratify=y,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    models = {\n",
    "        \"Logistic Regression\": (\n",
    "            LogisticRegression(max_iter=2000),\n",
    "            {\"C\": [0.01, 0.1, 1, 10]},\n",
    "            True\n",
    "        ),\n",
    "        \"SVM\": (\n",
    "            SVC(probability=True),\n",
    "            {\"C\": [0.1, 1, 10], \"kernel\": [\"rbf\", \"linear\"]},\n",
    "            True\n",
    "        ),\n",
    "        \"Random Forest\": (\n",
    "            RandomForestClassifier(class_weight=\"balanced\"),\n",
    "            {\n",
    "                \"n_estimators\": [200, 300],\n",
    "                \"max_depth\": [None, 10, 20],\n",
    "                \"min_samples_split\": [2, 5]\n",
    "            },\n",
    "            False\n",
    "        ),\n",
    "        \"XGBoost\": (\n",
    "            XGBClassifier(\n",
    "                objective=\"binary:logistic\",\n",
    "                eval_metric=\"logloss\",\n",
    "                use_label_encoder=False\n",
    "            ),\n",
    "            {\n",
    "                \"n_estimators\": [300, 500],\n",
    "                \"max_depth\": [3, 5, 7],\n",
    "                \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "                \"subsample\": [0.8, 1.0],\n",
    "                \"colsample_bytree\": [0.8, 1.0]\n",
    "            },\n",
    "            False\n",
    "        )\n",
    "    }\n",
    "\n",
    "    best_model = None\n",
    "    best_acc = 0\n",
    "    scores = {}\n",
    "\n",
    "    print(f\"\\nðŸš€ Training {model_name.upper()} (High Accuracy Mode)\")\n",
    "\n",
    "    for name, (model, params, needs_scaling) in models.items():\n",
    "\n",
    "        X_tr = X_train_scaled if needs_scaling else X_train\n",
    "        X_te = X_test_scaled if needs_scaling else X_test\n",
    "\n",
    "        grid = GridSearchCV(\n",
    "            model,\n",
    "            params,\n",
    "            cv=cv,\n",
    "            scoring=\"accuracy\",\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        grid.fit(X_tr, y_train)\n",
    "\n",
    "        preds = grid.predict(X_te)\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        scores[name] = acc\n",
    "\n",
    "        print(f\"{name}: {acc:.4f}\")\n",
    "        print(f\"   Best Params â†’ {grid.best_params_}\")\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_model = (grid.best_estimator_, needs_scaling)\n",
    "\n",
    "    # Save best model\n",
    "    with open(f\"{model_name}_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump({\n",
    "            \"model\": best_model[0],\n",
    "            \"scaler\": scaler if best_model[1] else None,\n",
    "            \"encoders\": encoders\n",
    "        }, f)\n",
    "\n",
    "    print(\"\\nðŸ“Š ACCURACY SUMMARY\")\n",
    "    for k, v in scores.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "    print(f\"\\nâœ… Saved {model_name}_model.pkl | BEST Accuracy: {best_acc:.4f}\")\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b88641",
   "metadata": {},
   "source": [
    "# SECTION 3: Save the Model and Checking the best Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96ce6845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Training HEART (High Accuracy Mode)\n",
      "Logistic Regression: 0.8098\n",
      "   Best Params â†’ {'C': 0.1}\n",
      "SVM: 0.8370\n",
      "   Best Params â†’ {'C': 1, 'kernel': 'rbf'}\n",
      "Random Forest: 0.8098\n",
      "   Best Params â†’ {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\training.py:199: UserWarning: [00:58:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost: 0.8261\n",
      "   Best Params â†’ {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300, 'subsample': 1.0}\n",
      "\n",
      "ðŸ“Š ACCURACY SUMMARY\n",
      "Logistic Regression: 0.8098\n",
      "SVM: 0.8370\n",
      "Random Forest: 0.8098\n",
      "XGBoost: 0.8261\n",
      "\n",
      "âœ… Saved heart_model.pkl | BEST Accuracy: 0.8370\n",
      "\n",
      "ðŸš€ Training DIABETES (High Accuracy Mode)\n",
      "Logistic Regression: 0.7078\n",
      "   Best Params â†’ {'C': 0.1}\n",
      "SVM: 0.8377\n",
      "   Best Params â†’ {'C': 1, 'kernel': 'rbf'}\n",
      "Random Forest: 0.8766\n",
      "   Best Params â†’ {'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\training.py:199: UserWarning: [00:58:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost: 0.8831\n",
      "   Best Params â†’ {'colsample_bytree': 1.0, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500, 'subsample': 1.0}\n",
      "\n",
      "ðŸ“Š ACCURACY SUMMARY\n",
      "Logistic Regression: 0.7078\n",
      "SVM: 0.8377\n",
      "Random Forest: 0.8766\n",
      "XGBoost: 0.8831\n",
      "\n",
      "âœ… Saved diabetes_model.pkl | BEST Accuracy: 0.8831\n",
      "\n",
      "ðŸš€ Training CANCER (High Accuracy Mode)\n",
      "Logistic Regression: 0.9649\n",
      "   Best Params â†’ {'C': 1}\n",
      "SVM: 0.9737\n",
      "   Best Params â†’ {'C': 10, 'kernel': 'rbf'}\n",
      "Random Forest: 0.9737\n",
      "   Best Params â†’ {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\training.py:199: UserWarning: [00:58:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost: 0.9737\n",
      "   Best Params â†’ {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 500, 'subsample': 0.8}\n",
      "\n",
      "ðŸ“Š ACCURACY SUMMARY\n",
      "Logistic Regression: 0.9649\n",
      "SVM: 0.9737\n",
      "Random Forest: 0.9737\n",
      "XGBoost: 0.9737\n",
      "\n",
      "âœ… Saved cancer_model.pkl | BEST Accuracy: 0.9737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.9649122807017544,\n",
       " 'SVM': 0.9736842105263158,\n",
       " 'Random Forest': 0.9736842105263158,\n",
       " 'XGBoost': 0.9736842105263158}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_save_model(\n",
    "    csv_path=\"datasets/heart.csv\",\n",
    "    target_col=\"num\",\n",
    "    model_name=\"heart\"\n",
    ")\n",
    "\n",
    "train_and_save_model(\n",
    "    csv_path=\"datasets/diabetes.csv\",\n",
    "    target_col=\"Outcome\",\n",
    "    model_name=\"diabetes\"\n",
    ")\n",
    "\n",
    "train_and_save_model(\n",
    "    csv_path=\"datasets/breast_cancer.csv\",\n",
    "    target_col=\"diagnosis\",\n",
    "    model_name=\"cancer\",\n",
    "    drop_cols=[\"id\", \"Unnamed: 32\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b83a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Saved heart_model.pkl | BEST Accuracy: 0.8370\n",
    "# âœ… Saved diabetes_model.pkl | BEST Accuracy: 0.8831\n",
    "# âœ… Saved cancer_model.pkl | BEST Accuracy: 0.9737"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
